import requests
import psycopg2
import time
import re
from datetime import datetime, timedelta
from config import DB_CONFIG, KEYWORDS, GEO_CONFIG

class HHParser:
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'HH-Parser/1.0',
            'Accept': 'application/json'
        })
    
    def clean_text(self, text):
        """–ü—Ä–æ—Å—Ç–∞—è –∏ –Ω–∞–¥–µ–∂–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ —á–µ—Ä–µ–∑ encode/decode"""
        if not text:
            return ""
        
        try:
            cleaned_text = text.encode('utf-8', 'ignore').decode('utf-8')
            cleaned_text = re.sub(r'[^\w\s\.\,\-\+\!\?\:\;\(\)\"\']', '', cleaned_text)
            return cleaned_text.strip()
        except:
            return ""
    
    def clean_html_tags(self, text):
        """–û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –æ—Ç HTML —Ç–µ–≥–æ–≤"""
        if not text:
            return ""
        
        text = re.sub(r'(\w+)>', r'<\1>', text)
        clean_text = re.sub(r'</?[^>]*>', '', text)
        
        html_entities = {
            '&nbsp;': ' ', '&amp;': '&', '&lt;': '<', 
            '&gt;': '>', '&quot;': '"', '&apos;': "'"
        }
        for entity, replacement in html_entities.items():
            clean_text = clean_text.replace(entity, replacement)
        
        clean_text = re.sub(r'\s+', ' ', clean_text)
        return clean_text.strip()
    
    def extract_skills_from_text(self, text):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –Ω–∞–≤—ã–∫–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        if not text:
            return "–Ω–µ —É–∫–∞–∑–∞–Ω—ã"
        
        text_lower = text.lower()
        tech_keywords = [
            'python', 'sql', 'excel', 'n8n', 'make.com', 'zapier', 'airflow', 
            'power bi', 'tableau', 'superset', 'metabase', 'vba', 'pandas',
            'numpy', 'etl', 'api', 'docker', 'git', 'postgresql', 'mysql',
            'selenium', 'postman', 'jira', 'confluence'
        ]
        
        found_skills = []
        for keyword in tech_keywords:
            if keyword in text_lower:
                found_skills.append(keyword)
        
        return ', '.join(found_skills) if found_skills else '–Ω–µ —É–∫–∞–∑–∞–Ω—ã'
    
    def check_work_format(self, vacancy_item, vacancy_detail):
        """–û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–æ—Ä–º–∞—Ç —Ä–∞–±–æ—Ç—ã"""
        schedule = vacancy_item.get('schedule', {})
        schedule_id = schedule.get('id')
        
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º schedule.id
        if schedule_id == 'remote':
            return 'remote'
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ —É–¥–∞–ª–µ–Ω–∫—É
        name = vacancy_item.get('name', '').lower()
        desc = vacancy_detail.get('description', '').lower()
        text = f"{name} {desc}"
        
        remote_keywords = ['—É–¥–∞–ª–µ–Ω', 'remote', '–¥–∏—Å—Ç–∞–Ω—Ü–∏–æ–Ω', 'work from home', '—É–¥–∞–ª—ë–Ω']
        if any(keyword in text for keyword in remote_keywords):
            return 'remote'
        
        # –í—Å–µ –æ—Å—Ç–∞–ª—å–Ω–æ–µ - –æ—Ñ–∏—Å (–≤–∫–ª—é—á–∞—è –≥–∏–±—Ä–∏–¥)
        return 'office'
    
    def parse_salary(self, salary_data):
        """–ö–æ—Ä—Ä–µ–∫—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞—Ä–ø–ª–∞—Ç—ã"""
        if not salary_data:
            return None, None
        
        salary_from = salary_data.get('from')
        salary_to = salary_data.get('to')
        
        if salary_data.get('currency') != 'RUR':
            if salary_from:
                salary_from = salary_from * 70
            if salary_to:
                salary_to = salary_to * 70
        
        return salary_from, salary_to
    
    def categorize_vacancy(self, vacancy):
        """–ö–∞—Ç–µ–≥–æ—Ä–∏–∑–∞—Ü–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ñ–∏–≥–∞ —Å –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞–º–∏"""
        title = vacancy['name'].lower()
        desc = vacancy.get('description', '').lower()
        skills = vacancy.get('skills', '').lower()
        
        text = f" {title} {desc} {skills} "
        
        from config import CATEGORIES
        sorted_categories = sorted(CATEGORIES.items(), key=lambda x: x[1]['priority'])
        
        for category_name, category_data in sorted_categories:
            keywords = category_data['keywords']
            
            has_keywords = any(f' {kw} ' in text for kw in keywords)
            
            if 'exclude' in category_data:
                has_exclude = any(f' {kw} ' in text for kw in category_data['exclude'])
                if has_keywords and not has_exclude:
                    return category_name
            else:
                if has_keywords:
                    return category_name
        
        return 'other'
    
    def calculate_relevance(self, vacancy, work_format):
        """–†–∞—Å—á–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ —Å —É—á–µ—Ç–æ–º –ª–æ–∫–∞—Ü–∏–∏"""
        score = 0
        title = vacancy['name'].lower()
        desc = vacancy.get('description', '').lower()
        skills = vacancy.get('skills', '').lower()
        
        text = f"{title} {desc} {skills}"
        
        high_priority = ['n8n', 'airflow', 'superset', 'power bi', 'tableau', 'etl', 'dbt']
        medium_priority = ['python', 'sql', 'pandas', 'vba', 'excel', 'dashboard']
        low_priority = ['data', 'analysis', '–∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü', '–∞–Ω–∞–ª–∏–∑']
        
        for keyword in high_priority:
            if keyword in text:
                score += 3
        
        for keyword in medium_priority:
            if keyword in text:
                score += 2
                
        for keyword in low_priority:
            if keyword in text:
                score += 1
        
        # –ë–æ–Ω—É—Å –∑–∞ —É–∫–∞–∑–∞–Ω–∏–µ –∑–∞—Ä–ø–ª–∞—Ç—ã
        if vacancy.get('salary_from') or vacancy.get('salary_to'):
            score += 2
        
        # –ë–æ–Ω—É—Å –∑–∞ –ø–æ–¥—Ö–æ–¥—è—â–∏–π —Ñ–æ—Ä–º–∞—Ç —Ä–∞–±–æ—Ç—ã
        if work_format == 'remote':
            score += 3
        elif work_format == 'hybrid':
            score += 2
        elif work_format == 'office':
            score += 1
            
        return min(score, 10)
    
    def get_vacancy_details(self, vacancy_id):
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –≤–∞–∫–∞–Ω—Å–∏–∏"""
        try:
            response = self.session.get(
                f"https://api.hh.ru/vacancies/{vacancy_id}",
                timeout=10
            )
            if response.status_code == 200:
                return response.json()
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –¥–µ—Ç–∞–ª–µ–π –≤–∞–∫–∞–Ω—Å–∏–∏ {vacancy_id}: {e}")
        return {}
    
    def get_hh_vacancies(self):
        """–ó–∞–≥—Ä—É–∂–∞–µ–º –í–°–ï –≤–∞–∫–∞–Ω—Å–∏–∏ –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º -> —Ñ–∏–ª—å—Ç—Ä—É–µ–º –Ω–∞ –Ω–∞—à–µ–π —Å—Ç–æ—Ä–æ–Ω–µ"""
        url = "https://api.hh.ru/vacancies"
        all_vacancies = []
        
        # –û–î–ò–ù –±–æ–ª—å—à–æ–π –∑–∞–ø—Ä–æ—Å - –í–°–ï –≤–∞–∫–∞–Ω—Å–∏–∏ –†–æ—Å—Å–∏–∏
        params = {
            'text': 'python OR sql OR vba OR excel OR –∞–Ω–∞–ª–∏—Ç–∏–∫ OR –¥–∞–Ω–Ω—ã–µ OR —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫ OR —Ç–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫ OR 1—Å OR –±—É—Ö–≥–∞–ª—Ç–µ—Ä OR –æ–ø–µ—Ä–∞—Ç–æ—Ä OR —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç OR BI –∞–Ω–∞–ª–∏—Ç–∏–∫ OR n8n OR Airflow OR superset ',  # –®–∏—Ä–æ–∫–∏–π –æ—Ö–≤–∞—Ç
            'area': 113,  # –í—Å—è –†–æ—Å—Å–∏—è
            'per_page': 100,  # –ú–∞–∫—Å–∏–º—É–º –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ
            'page': 0,
            'period': 7,  # –¢–æ–ª—å–∫–æ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π (—Å–≤–µ–∂–∏–µ)
        }
        
        print("üîç –ó–∞–≥—Ä—É–∂–∞–µ–º –í–°–ï –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –≤–∞–∫–∞–Ω—Å–∏–∏ –†–æ—Å—Å–∏–∏ –∑–∞ 7 –¥–Ω–µ–π...")
        
        try:
            response = self.session.get(url, params=params, timeout=15)
            data = response.json()
            
            found = data.get('found', 0)
            pages = data.get('pages', 1)
            
            print(f"üì® –ù–∞–π–¥–µ–Ω–æ –≤–∞–∫–∞–Ω—Å–∏–π –ø–æ –∑–∞–ø—Ä–æ—Å—É: {found}")
            print(f"üìÑ –°—Ç—Ä–∞–Ω–∏—Ü –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {pages}")
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –í–°–ï —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            for page in range(pages):
                if page > 0:  # –ü–µ—Ä–≤—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É —É–∂–µ –∑–∞–≥—Ä—É–∑–∏–ª–∏
                    params['page'] = page
                    response = self.session.get(url, params=params, timeout=15)
                    data = response.json()
                
                print(f"üìñ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page + 1}/{pages}")
                
                page_count = 0
                for item in data.get('items', []):
                    try:
                        # –ë–∞–∑–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
                        city = item.get('area', {}).get('name', '–ù–µ —É–∫–∞–∑–∞–Ω')
                        vacancy_id = item['id']
                        
                        # üî• –§–ò–õ–¨–¢–† 1: –§–æ—Ä–º–∞—Ç —Ä–∞–±–æ—Ç—ã
                        schedule_id = item.get('schedule', {}).get('id', '')
                        work_format = 'remote' if schedule_id == 'remote' else 'office'
                        
                        # –û–°–ù–û–í–ù–û–ô –§–ò–õ–¨–¢–†: –¢—é–º–µ–Ω—å - –≤—Å–µ, –¥—Ä—É–≥–∏–µ –≥–æ—Ä–æ–¥–∞ - —Ç–æ–ª—å–∫–æ —É–¥–∞–ª–µ–Ω–∫–∞
                        if city != '–¢—é–º–µ–Ω—å' and work_format != 'remote':
                            continue
                        
                        # üî• –§–ò–õ–¨–¢–† 2: –û–ø—ã—Ç —Ä–∞–±–æ—Ç—ã
                        experience_id = item.get('experience', {}).get('id', '')
                        if experience_id not in ['noExperience', 'between1And3']:
                            continue
                        
                        # üî• –§–ò–õ–¨–¢–† 3: –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏
                        name = item.get('name', '').lower()
                        
                        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ø–∏—Å–æ–∫ –ø—Ä–æ—Ñ–µ—Å—Å–∏–π
                        target_keywords = [
                            'python', 'sql', 'excel', 'n8n', 'airflow', 'power bi', 'tableau',
                            'data', '–∞–Ω–∞–ª–∏—Ç–∏–∫', '–∞–Ω–∞–ª–∏–∑', '–¥–∞–Ω–Ω', 'etl', 'dash', '–¥–∞—à–±–æ—Ä–¥',
                            'qa', '—Ç–µ—Å—Ç–∏—Ä–æ–≤—â–∏–∫', '—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ', 'testing', 
                            '1—Å', '–±—É—Ö–≥–∞–ª—Ç–µ—Ä', '–æ–ø–µ—Ä–∞—Ç–æ—Ä', '—Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç',
                            '–∞—Ä—Ö–∏–≤–∞—Ä–∏—É—Å', '–¥–µ–ª–æ–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å', '–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü', '–∞—Ä—Ö–∏–≤',
                            'confluence', '–∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü', 'rpa', 'workflow',
                            '–º–µ–Ω–µ–¥–∂–µ—Ä', '–∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä', '–∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä', '–ø–æ–º–æ—â–Ω–∏–∫'
                        ]
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å –ª—é–±—ã–º –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–æ–º
                        has_keyword = any(keyword in name for keyword in target_keywords)
                        if not has_keyword:
                            continue
                        
                        # üî• –í–°–ï —Ñ–∏–ª—å—Ç—Ä—ã –ø—Ä–æ–π–¥–µ–Ω—ã - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤–∞–∫–∞–Ω—Å–∏—é
                        
                        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞—Ä–ø–ª–∞—Ç—ã
                        salary_data = item.get('salary')
                        salary_from = None
                        salary_to = None
                        
                        if salary_data:
                            salary_from = salary_data.get('from')
                            salary_to = salary_data.get('to')
                            
                            if salary_data.get('currency') != 'RUR':
                                if salary_from:
                                    salary_from = salary_from * 70
                                if salary_to:
                                    salary_to = salary_to * 70
                        
                        # –ü–æ–ª—É—á–∞–µ–º –ø–æ–ª–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ
                        vacancy_detail = self.get_vacancy_details(vacancy_id)
                        full_description = ""
                        
                        if vacancy_detail:
                            raw_description = vacancy_detail.get('description', '')
                            full_description = self.clean_html_tags(raw_description)[:2000]
                        
                        # –§–æ—Ä–º–∏—Ä—É–µ–º –≤–∞–∫–∞–Ω—Å–∏—é
                        vacancy = {
                            'hh_id': int(vacancy_id),
                            'name': self.clean_text(item['name']),
                            'company': self.clean_text(item['employer']['name']),
                            'salary_from': salary_from,
                            'salary_to': salary_to,
                            'url': item['alternate_url'],
                            'skills': ', '.join([s['name'] for s in item.get('key_skills', [])]),
                            'description': full_description,
                            'work_format': work_format,
                            'city': city
                        }
                        
                        vacancy['category'] = self.categorize_vacancy(vacancy)
                        vacancy['relevance_score'] = self.calculate_relevance(vacancy, work_format)
                        
                        all_vacancies.append(vacancy)
                        page_count += 1
                        print(f"‚úÖ {city}: {vacancy['name'][:50]}... | {work_format}")
                        
                    except Exception as e:
                        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∞–∫–∞–Ω—Å–∏–∏: {e}")
                        continue
                
                print(f"üìä –ù–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ {page + 1} –¥–æ–±–∞–≤–ª–µ–Ω–æ: {page_count} –≤–∞–∫–∞–Ω—Å–∏–π")
                
                # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º–∏
                if page < pages - 1:
                    time.sleep(0.5)
            
            print(f"\nüéØ –ò–¢–û–ì–û –Ω–∞–π–¥–µ–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –≤–∞–∫–∞–Ω—Å–∏–π: {len(all_vacancies)}")
            
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
            import traceback
            traceback.print_exc()
        
        return all_vacancies

def save_to_db(vacancies):
    """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–∞–∫–∞–Ω—Å–∏–π –≤ –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö"""
    conn = psycopg2.connect(**DB_CONFIG)
    cursor = conn.cursor()
    
    new_count = 0
    duplicate_count = 0
    error_count = 0
    
    for vac in vacancies:
        try:
            cursor.execute("""
                INSERT INTO vacancies 
                (hh_id, name, company, salary_from, salary_to, url, skills, 
                 description, category, relevance_score, work_format, city)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                ON CONFLICT (hh_id) DO NOTHING
                RETURNING id
            """, (
                vac['hh_id'], vac['name'], vac['company'], vac['salary_from'], 
                vac['salary_to'], vac['url'], vac['skills'], vac['description'],
                vac['category'], vac['relevance_score'], vac['work_format'], vac['city']
            ))
            
            if cursor.fetchone():
                new_count += 1
            else:
                duplicate_count += 1
                
        except Exception as e:
            error_count += 1
            print(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –≤–∞–∫–∞–Ω—Å–∏–∏ {vac['hh_id']}: {e}")
    
    conn.commit()
    cursor.close()
    conn.close()
    
    return new_count, duplicate_count, error_count

if __name__ == "__main__":
    print(f"üïí {datetime.now()} - –ó–∞–ø—É—Å–∫ –û–ü–¢–ò–ú–ò–ó–ò–†–û–í–ê–ù–ù–û–ì–û –ø–∞—Ä—Å–µ—Ä–∞ HH.ru")
    print(f"üìç –ì–µ–æ-—Ñ–∏–ª—å—Ç—Ä: –¢—é–º–µ–Ω—å - –ª—é–±–æ–π —Ñ–æ—Ä–º–∞—Ç, –¥—Ä—É–≥–∏–µ –≥–æ—Ä–æ–¥–∞ - —Ç–æ–ª—å–∫–æ —É–¥–∞–ª–µ–Ω–∫–∞")
    print(f"üíº –û–ø—ã—Ç: –±–µ–∑ –æ–ø—ã—Ç–∞ –∏–ª–∏ 1-3 –≥–æ–¥–∞")
    print("=" * 60)
    
    parser = HHParser()
    vacancies = parser.get_hh_vacancies()
    
    print(f"\nüéØ –ù–∞–π–¥–µ–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –≤–∞–∫–∞–Ω—Å–∏–π: {len(vacancies)}")
    
    if vacancies:
        new_count, duplicate_count, error_count = save_to_db(vacancies)
        print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: –Ω–æ–≤—ã—Ö {new_count}, –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ {duplicate_count}, –æ—à–∏–±–æ–∫ {error_count}")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ñ–æ—Ä–º–∞—Ç–∞–º —Ä–∞–±–æ—Ç—ã
        formats = {}
        for vac in vacancies:
            fmt = vac['work_format']
            formats[fmt] = formats.get(fmt, 0) + 1
        
        print("\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ñ–æ—Ä–º–∞—Ç–∞–º —Ä–∞–±–æ—Ç—ã:")
        for fmt, count in formats.items():
            print(f"  {fmt}: {count} –≤–∞–∫–∞–Ω—Å–∏–π")
    else:
        print("‚ùå –ü–æ–¥—Ö–æ–¥—è—â–∏—Ö –≤–∞–∫–∞–Ω—Å–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")